{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport random\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport glob\nimport PIL.Image as Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch import Tensor\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.utils as vutils\nfrom torchvision import datasets, transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Architecture","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self,\n                latent_space : int = 100,\n                ) -> None:\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            # Input : 100\n            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(True),\n    \n            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=True),\n            nn.Tanh()\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        out = self.main(x)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class : ConvBlock\nclass ConvBlock(nn.Module):\n    def __init__(self,\n                in_channels : int = 3,\n                out_channels : int = 128,\n                kernel_size : int = 4,\n                stride : int = 2, \n                padding : int = 1,\n                bias : bool = False,\n                ) -> None:\n        super(ConvBlock, self).__init__()\n        \n        self.block = nn.Sequential(\n            nn.Conv2d(in_channels = in_channels,\n                     out_channels = out_channels,\n                     kernel_size = kernel_size,\n                     stride = stride,\n                     padding = padding,\n                     bias = bias),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(0.2, inplace = True),\n        )\n    def forward(self,\n                x : Tensor,\n               ) -> Tensor :\n        out = self.block(x)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class : Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self,\n                channels : list = [128, 256, 512],\n                ) -> None:\n        super(Discriminator, self).__init__()\n        \n        # Top layer\n        self.top = nn.Sequential(\n            nn.Conv2d(in_channels = 3,\n                      out_channels = 64,\n                      kernel_size = 4,\n                      stride = 2,\n                     padding = 1,),\n            nn.LeakyReLU(0.2, inplace = True),\n        \n        )\n        \n        # Block of layers\n        blocks = []\n        in_channels = 64\n        for i in range(len(channels)):\n            blocks.append(ConvBlock(in_channels = in_channels, out_channels = channels[i]))\n            in_channels = channels[i]\n        self.blocks = nn.Sequential(*blocks)\n        \n        # Bottom layer\n        self.bottom = nn.Sequential(\n            nn.Conv2d(in_channels = 512,\n                      out_channels = 1,\n                      kernel_size = 4,\n                      stride = 1,\n                     padding = 0,),\n            nn.Sigmoid(),\n        )\n    def forward(self, x : Tensor) -> Tensor:\n        out = self.top(x)\n        out = self.blocks(out)\n        out = self.bottom(out)\n        out = torch.flatten(out, 1)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize weights of layers\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if (classname.find(\"Conv2d\") or classname.find('ConvTranspose2d')) != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"class CalebDataset(nn.Module):\n    def __init__(self,\n                 datapath : str,\n                 image_size : int = 64,\n                ) -> None:\n        super(CalebDataset, self).__init__()\n        \n        self.image_size = image_size\n        # List of images ends with .jpg\n        self.images = sorted(glob.glob(datapath+\"/*.jpg\"))\n        \n        self.transform = transforms.Compose([\n            transforms.Resize((self.image_size, self.image_size),\n                              transforms.InterpolationMode.BICUBIC),\n            transforms.ToTensor(),\n        ])\n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, index):\n        images =  self.transform(Image.open(self.images[index % len(self.images)]))\n        return images, index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"def build_model(args):\n    generator = Generator(args.latent_space).to(args.device)\n    discriminator = Discriminator().to(args.device)\n    \n    return generator, discriminator\n\ndef load_dataset(args\n                ) :\n    \n    loader = DataLoader(CalebDataset(args.datapath,\n                                      args.image_size,\n                                     ),\n                        batch_size = args.batch_size,\n                        shuffle = True,\n                       )\n    return loader\n\ndef loss_function():\n    adversarial_loss = nn.BCELoss().to(args.device)\n    \n    return adversarial_loss\n    \ndef optimizer(generator, discriminator, args):\n    optimizer_g = optim.Adam(generator.parameters(), lr = args.lr, betas = (args.b1, args.b2))\n    optimizer_d = optim.Adam(discriminator.parameters(), lr = args.lr, betas = (args.b1, args.b2))\n    \n    return optimizer_g, optimizer_d","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"def trainer(loader,\n            generator,\n            discriminator,\n            optimizer_g,\n            optimizer_d,\n            loss_fn,\n            args,\n           ):\n    \"\"\" Training Generative Adversarial Networks \"\"\"\n    \n    # list to keep track of progress\n    g_losses = []\n    d_losses = []\n    \n    start = datetime.now()\n    \n    # set model in training model\n    generator.train()\n    discriminator.train()\n    \n\n    \n    for epoch in range(1, args.epochs):\n        for index, (real, _) in enumerate(loader):\n            #flatten\n            real = real.to(args.device)\n            size = real.size(0)\n            # create ground truth. set real sample level to 1 and fake sample level to 0\n            real_sample = torch.full([size, 1], 1.0, dtype=real.dtype, device=args.device)\n            fake_sample = torch.full([size, 1], 0.0, dtype=real.dtype, device=args.device)\n            \n            # create a noise sample for generator input\n            noise = torch.randn([size, 100, 1, 1], device = args.device)\n            \n            \"\"\" Train Discriminator\"\"\"\n            # initialize discriminator model gradients\n            discriminator.zero_grad()\n            # calculate loss of discriminator model on real images\n            output = discriminator(real)\n            loss_real_d = loss_fn(output, real_sample)\n            # calculate gradient of discriminator in backward pass\n            loss_real_d.backward()\n            D_x = output.mean().item()\n            \n            # generate fake image\n            fake = generator(noise)\n            # calculate loss of discriminator model on fake images\n            output = discriminator(fake.detach())\n            loss_fake_d = loss_fn(output, fake_sample)\n            # calculate gradient of discriminator for this batch summed with previous gradient\n            loss_fake_d.backward()\n            D_G_z1 = output.mean().item()\n            # calculate loss of discriminator model as sum on both real images and fake images\n            loss_d = loss_real_d + loss_fake_d\n            # update weight of discriminator model\n            optimizer_d.step()\n            \n            \"\"\" Train Generator \"\"\"\n            # initialize generator model gradient\n            generator.zero_grad()\n            # calculate the loss of discriminator model on fake images\n            output = discriminator(fake)\n            loss_g = loss_fn(output, real_sample)\n            # calculate gradient of generator\n            loss_g.backward()\n            D_G_z2 = output.mean().item()\n            # update weight of generator model\n            optimizer_g.step()\n            \n            # save images to see training stability\n            if index == 0:\n                vutils.save_image(vutils.make_grid(fake, normalize = False), os.path.join(args.outputs_dir, f\"fake_image_{epoch}.jpg\"))\n                vutils.save_image(vutils.make_grid(real, normalize = False), os.path.join(args.outputs_dir, f\"real_image_{epoch}.jpg\"))\n                \n            # Print the loss function every ten iterations and the last iteration in this epoch.\n            if index % 10 == 0 or index == len(loader):\n                print(f\"Train stage: adversarial \"\n                      f\"Epoch[{epoch:04d}/{args.epochs:04d}]({index:05d}/{len(loader):05d}) \"\n                      f\"D Loss: {loss_d.item():.6f} G Loss: {loss_g.item():.6f} \"\n                      f\"D(D_x): {D_x:.6f} D(D_G_z1)/D(D_G_z2): {D_G_z1:.6f}/{D_G_z2:.6f}.\")\n            \n            # save losses for plotting later\n            g_losses.append(loss_g.item())\n            d_losses.append(loss_d.item())\n        print(\"Training complete in: \" + str(datetime.now() - start))\n        \n    return g_losses, d_losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"class ARGS():\n    outputs_dir = 'output'\n    datapath = \"../input/celeba-dataset/img_align_celeba/img_align_celeba\"\n    latent_space = 100\n    image_size = 64\n    batch_size = 256\n    epochs = 20\n    b1 = 0.5\n    b2 = 0.99\n    lr = 0.002\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    outputs_dir = os.path.join(outputs_dir,  \"dcgan\")\n    if not os.path.exists(outputs_dir):\n        os.makedirs(outputs_dir)\n    \n    seed = 42\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nargs = ARGS()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"def main(args):\n    loader = load_dataset(args)\n    print('Loaded dataset successfully')\n    generator, discriminator = build_model(args)\n    print('Built model successfully')\n    \n    # Weight Initialization\n    # weight's initialization\n    generator.apply(weights_init)\n    discriminator.apply(weights_init)\n    \n    print('Weights initialize successfully')\n    \n    \n    loss_fn = loss_function()\n    print('Define loss function succesfully')\n    optimizer_g, optimizer_d = optimizer(generator, discriminator,args)\n    print('Define all optimization function successfully')\n    \n    # training\n    g_losses, d_losses = trainer(loader, generator, discriminator,\n                                 optimizer_g, optimizer_d, loss_fn, args)\n    \n    plt.figure(figsize=(10,5))\n    plt.title(\"Generator and Discriminator Loss During Training\")\n    plt.plot(g_losses,label=\"G\")\n    plt.plot(d_losses,label=\"D\")\n    plt.xlabel(\"iterations\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main(args)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}